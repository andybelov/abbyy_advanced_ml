# Задание 1 — FastText spellchecking
## Преамбула
27 октября была прочитана [лекция](https://github.com/andybelov/abbyy_advanced_ml/blob/master/Lectures/4_Embeddings.pdf ) об эмбеддингах всех сортов. В ней подробно разбиралась skip-gram-архитектура *word2vec* и упоминалась библиотека *fasttext* как аналог и даже усовершенствование w2v.

В задании предлагается попробовать применить эмбеддинги, полученные с помощью этой модели, для спеллчекинга, сравниться с базовым алгоритмом и описать, что получилось.

## Базовый алгоритм

[Здесь](http://norvig.com/spell-correct.html) подробно описан простой метод исправления ошибок, основанный на noisy channel model, а также представлены результаты оценки его качества на [валидационной](http://norvig.com/spell-testset1.txt) и [тестовой](http://norvig.com/spell-testset1.txt) выборках.

Реализуйте алгоритм с помощью доступного по ссылке кода и проверьте, что качество исправления ошибок совпадает с заявленным автором.

## Как работать с FastText
### Через Python-библиотеку gensim
1. Установить библиотеку *gensim* для работы с предобученными моделями эмбеддингов
2. Скачать [модель поменьше](https://s3-us-west-1.amazonaws.com/fasttext-vectors/wiki-news-300d-1M-subword.vec.zip) или [модель побольше](https://s3-us-west-1.amazonaws.com/fasttext-vectors/wiki.en.zip) — в зависимости от доступных ресурсов.
3. Первую модель грузить так:
```python
from gensim.models.wrappers import FastText
model = FastText.load_word2vec_format('FILENAME.vec')
```
4. Вторую:
```python
from gensim.models.wrappers import FastText
model = FastText.load_fasttext_format(filename_without_extension)
```
Если использовать первую модель, то эмбеддинги можно будет получать только для слов, которые встречались в корпусе при её обучении. Если вторую — для любых слов.

### Через командную строку
Этот способ предполагает наличие Linux / MacOS. Модель не грузится в память целиком, поэтому можно использовать вторую (бОльшую) модель и не бояться, что ресурсов не хватит. Из минусов — теряются плюшки, встроенные в классы библиотеки *gensim*.

1. Установить fasttext с помощью make, как описано по [ссылке](https://github.com/facebookresearch/fastText). 
2. Для общения с моделью из Python можно использовать следующий [сниппет](https://github.com/salestock/fastText.py/issues/115#issuecomment-339573398) кода.

## Что нужно сделать
Использовать вектора fasttext-модели (и функционал *gensim*) произвольным образом (за исключением применения глубоких архитектур) и побить базовый алгоритм. Так, например, можно вспомнить, что skip-gram — это, прежде всего, языковая модель, которую можно использовать вместо языковой модели в базовом алгоритме.

Если удалось добиться хороших результатов на предлагаемом датасете, подумайте, как можно было бы реализовать спеллчекер, которому на вход подаётся не отдельное слово, а целый контекст (датасет для оценки качества в этом случае нужно сгенерировать самим, это должно быть несложно). Помните, что мы не хотим исправлять слова, в которых нет ошибок!

Наиболее оригинальные и эффективные решения основной задачи, а также решения задачи спеллчекинга на контекстах получат дополнительные баллы.

## Дедлайн
Ноутбуки с результатами экспериментов можно присылать на [alexey.romanov@phystech.edu](alexey.romanov@phystech.edu) до 23:59 24.11.2017.
